<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="generator" content="Hugo 0.62.2" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
    <link rel="stylesheet" href="css/normalize.css">
    <link rel="stylesheet" href="css/skeleton.css">
    <link rel="stylesheet" href="css/custom.css">
    <link rel="stylesheet" href="css/toc.css">
    <link rel="stylesheet" href="css/collapsible.css">
    <!-- <link rel="alternate" href="index.xml" type="application/rss+xml" title="PopMAG"> -->
    <link rel="shortcut icon" href="favicon.png" type="image/x-icon" />
    <title>Rebuttal | Museformer</title>

    <script>
        window.addEventListener('DOMContentLoaded', () => {

            const observer = new IntersectionObserver(entries => {
                entries.forEach(entry => {
                    const id = entry.target.getAttribute('id');
                    if (entry.intersectionRatio > 0) {
                        document.querySelector(`nav li a[href="#${id}"]`).parentElement.classList.add('active');
                    } else {
                        document.querySelector(`nav li a[href="#${id}"]`).parentElement.classList.remove('active');
                    }
                });
            });

            // Track all sections that have an `id` applied
            document.querySelectorAll('section[id]').forEach((section) => {
                observer.observe(section);
            });

        });
    </script>
</head>

<body>

    <div>

        <header role="banner">

        </header>


        <main role="main">


            <div>
                <article itemscope itemtype="https://schema.org/BlogPosting">
                    <h1 class="entry-title" itemprop="headline">Museformer: Transformer with Fine- and Coarse-Grained
                        Attention for Music Generation</h1>

                    <div align="justify">
                        This page shows supplementary materials for rebuttal.
                    </div>

                    <div align="justify">
                        Click <a href="https://museformer.github.io/">here</a> to go to the original demo page.
                    </div>

                    <section id="introduction">
                        <h2>Introduction</h2>
                        <p>In this page, we will show:</p>
                        <p>- <a href="#dataset_analysis"><b>Similarity Distribution on Different Datasets</b></a>: to
                            show the generalization of the
                            structure-related bar selection to other genres and datasets.</p>
                        <p>- <a href="#music_analysis"><b>Similarity Distribution on Generated Music</b></a>: to provide
                            an objective comparison about
                            music structures among Museformer and the baseline models.</p>
                        <p>- <a href="#ssm"><b>Self-Similarity Matrix of Demos</b></a>: to visualize the music
                            structures of the demos and
                            to demonstrate that Museformer does not simply copy but can generate variations.</p>
                    </section>

                    <section id="dataset_analysis">
                        <h2>Similarity Distribution on Different Datasets</h2>
                        <p>To see the music structures of different genres and datasets and check whether our
                            structure-related bar pattern is widely applicable, we do the similarity statistics: We
                            compute the similarities between each pair of bars within a song, and see the similarity
                            distribution with respect to the distance between two bars. Here, the similarity is defined
                            as the number of the common notes over the size of the union set of notes of the two bars,
                            so its value should range from 0.0 to 1.0. Two notes are considered equal when their onsets
                            within their bars, pitches, and durations are all the same. For each song, we would obtain a
                            self-similarity matrix, whose size is num_bars X num_bars. Then, we compute the similarity
                            distribution with respect to the distance between two bars, which shows the average value of
                            similarities between two bars at each specific distance. The datasets and the results are as
                            follows.</p>

                        <section id="dataset_analysis_lmd">
                            <h3>LMD (TopMAGD)</h3>
                            The widely used MIDI dataset, Lakh MIDI (LMD), contains songs of various genres. The <a
                                href="http://www.ifs.tuwien.ac.at/mir/msd/TopMAGD.html">TopMAGD dataset</a> annotates
                            the genre labels to many songs, a part of which is matched to songs in LMD. There are
                            altogether 13 genres: Pop/Rock, Electronic, Rap, Jazz, Latin, R&B, International, Country,
                            Reggae, Blues, Vocal, Folk, and New Age. We utilize the genre labels provided by TopMAGD to
                            sort the LMD songs, and then do the statistics for each genre. The similarity is computed
                            for the melody track. The results are shown below. Note that we omit the similarity when
                            distance is 0, since it is always equal to 1.

                            These 13 genres should cover most songs we listen to in daily life. As you may see from the
                            figures, for all of the genres, the similarities at distance 1, 2, and multiples of 4 are
                            generally higher than others, which means music tend to repeat or largely refer to previous
                            bars at these distances. This demonstrates our selection of the structure-related bars in
                            the paper, i.e., the previous 1st, 2nd, 4th, 8th, 16th, 24th, 32th bars are selected as the
                            structure-related bars and are directly attended to via the fine-grained attention, is
                            general to various of genres.

                            <figure>
                                <figcaption>Pop Music</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Pop_Rock-basic-40.png">
                            </figure>

                            <figure>
                                <figcaption>Electronic</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Electronic-basic-1482-40.png">
                            </figure>

                            <figure>
                                <figcaption>Rap</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Rap-basic-186-40.png">
                            </figure>

                            <figure>
                                <figcaption>Jazz</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Jazz-basic-759-40.png">
                            </figure>

                            <figure>
                                <figcaption>Latin</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Latin-basic-758-40.png">
                            </figure>

                            <figure>
                                <figcaption>R&B</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/RnB-basic-1240-40.png">
                            </figure>

                            <figure>
                                <figcaption>International</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/International-basic-588-40.png">
                            </figure>

                            <figure>
                                <figcaption>Country</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Country-basic-1152-40.png">
                            </figure>

                            <figure>
                                <figcaption>Reggae</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Reggae-basic-41-40.png">
                            </figure>

                            <figure>
                                <figcaption>Blues</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Blues-basic-52-40.png">
                            </figure>

                            <figure>
                                <figcaption>Vocal</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Vocal-basic-365-40.png">
                            </figure>

                            <figure>
                                <figcaption>Folk</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/Folk-basic-103.png">
                            </figure>

                            <figure>
                                <figcaption>New Age</figcaption>
                                <img src="rebuttal_materials/similarity/lmd/NewAge-basic-258-40.png">
                            </figure>
                        </section>

                        <section id="dataset_analysis_symphony">
                            <h3>Symphony</h3>
                            We also do the same statistics on a large-scale <a
                                href="https://github.com/symphonynet/SymphonyNet">symphony dataset</a>. This dataset is
                            composed of classical and contemporary multi-track symphony performances. Since it is hard
                            to tell which is the melody track of a symphony performance, we use the average similarity
                            over all the tracks. The results are shown in the following figure. It shows that our
                            structure-related bar selection can also be reasonably applicable to this dataset.

                            <figure>
                                <figcaption>Symphony Dataset</figcaption>
                                <img src="rebuttal_materials/similarity/symphony/symphony.png">
                            </figure>
                        </section>

                        <br />
                        In conclusion, through these statistics results, we can see that our structure-related bar
                        selection can generalize to other genres and datasets, and should cover most of the music we
                        involve with in our daily life. Note that we only chose 8 bars as the structure-related bars
                        in our paper is because it is a trade-off between model performances and efficiency. <b>Our
                            high-level idea that fine-grained attention is for important contents and coarse-grained
                            attention is for other contextual information, is universally fittable for music data.
                            Our model can be easily adapted to more structure-related bars or even any other music
                            structures by simply changing a set of hyperparameters in the implementation.</b>
                    </section>

                    <section id="music_analysis">
                        <h2>Similarity Distribution on Generate Music</h2>
                        Using the same method described in <a href="#dataset_analysis">the last section</a>, we compute
                        the bar-pair similarity distribution on 100 music pieces generated by each model (Museformer and
                        the baseline models). The result is as follows:

                        <figure>
                            <figcaption>Music Transformer</figcaption>
                            <img src="rebuttal_materials/similarity_demo/mt_100demos.png">
                        </figure>

                        <figure>
                            <figcaption>Transformer-XL</figcaption>
                            <img src="rebuttal_materials/similarity_demo/xl_100demos.png">
                        </figure>

                        <figure>
                            <figcaption>Longformer</figcaption>
                            <img src="rebuttal_materials/similarity_demo/longformer_100demos.png">
                        </figure>

                        <figure>
                            <figcaption>Linear Transformer</figcaption>
                            <img src="rebuttal_materials/similarity_demo/linear_100demos.png">
                        </figure>

                        <figure>
                            <figcaption>Museformer</figcaption>
                            <img src="rebuttal_materials/similarity_demo/mf_100demos.png">
                        </figure>

                        <figure>
                            <figcaption>Training Data</figcaption>
                            <img src="rebuttal_materials/similarity_demo/training_set.png">
                        </figure>

                        The last figure shows the similarity distribution on the training data. The more the
                        distribution of generated music is like that of the training data, the better. As we can see
                        from the above figures: 1) Music Transformer that is trained with sequences of limited lengths
                        cannot generate music with good structures. 2) Linear Transformer that uses approximated
                        attention cannot well model the music structures even if the linearized attention allows a token
                        to see all of the previous tokens. 3) The generated music pieces by Transformer-XL or Longformer
                        manifest the similar distribution to that of the training data, yet it is still not good enough.
                        4) It is quite obvious that Museformer can generated music with structures close to the training
                        data. 5) Interestingly, we found that the similarity distribution results perfectly align with
                        the subjective evaluation results over the structures presented in Table 2 of the paper.

                    </section>

                    <section id="ssm">
                        <h2>Self-Similarity Matrix of Demos</h2>

                        Using the same method of similarity computation described <a href="#dataset_analysis">here</a>,
                        we visualize the self-similarity matrices of the Museformer demos on <a
                            href="https://museformer.github.io/">the demo page</a>, to vividly show the structures, as
                        well as our ability to generate music with variations instead of simply copying. The
                        similarities are computed over the melody track.

                        <section id="ssm_demo1">
                            <h3>Demo 1 (<a href="midi/mf/mf_demo1.mid">midi</a>)</h3>
                            <audio controls="controls">
                                <source src="audio/mf/mf_demo1.mp3" autoplay />Your browser does not support the audio
                                element.
                            </audio>
                            <figure>
                                <figcaption>Demo 1 (melody)</figcaption>
                                <img src="rebuttal_materials/ssm_demo/mf_demo1.png">
                            </figure>

                            <button class="collapsible">Show Other Tracks of Demo 1</button>
                            <div class="colla_content">
                                <figure>
                                    <figcaption>Demo 1 (piano)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo1_piano.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 1 (string)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo1_string.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 1 (bass)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo1_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 1 (percussion)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo1_percussion.png">
                                </figure>
                            </div>
                        </section>

                        <section id="ssm_demo2">
                            <h3>Demo 2 (<a href="midi/mf/mf_demo2.mid">midi</a>)</h3>
                            <audio controls="controls">
                                <source src="audio/mf/mf_demo2.mp3" autoplay />Your browser does not support the audio
                                element.
                            </audio>
                            <figure>
                                <figcaption>Demo 2 (melody)</figcaption>
                                <img src="rebuttal_materials/ssm_demo/mf_demo2.png">
                            </figure>

                            <button class="collapsible">Show Other Tracks of Demo 3</button>
                            <div class="colla_content">
                                <figure>
                                    <figcaption>Demo 2 (guitar)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo2_guitar.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 2 (string)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo2_string.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 2 (bass)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo2_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 2 (percussion)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo2_percussion.png">
                                </figure>
                            </div>

                        </section>

                        <section id="ssm_demo3">
                            <h3>Demo 3 (<a href="midi/mf/mf_demo3.mid">midi</a>)</h3>
                            <audio controls="controls">
                                <source src="audio/mf/mf_demo3.mp3" autoplay />Your browser does not support the audio
                                element.
                            </audio>
                            <figure>
                                <figcaption>Demo 3 (melody)</figcaption>
                                <img src="rebuttal_materials/ssm_demo/mf_demo3.png">
                            </figure>

                            <button class="collapsible">Show Other Tracks of Demo 3</button>
                            <div class="colla_content">
                                <figure>
                                    <figcaption>Demo 3 (piano)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo3_piano.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 3 (guitar)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo3_guitar.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 3 (bass)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo3_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 3 (percussion)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo3_percussion.png">
                                </figure>
                            </div>
                        </section>


                        <section id="ssm_demo4">
                            <h3>Demo 4 (<a href="midi/mf/mf_demo4.mid">midi</a>)</h3>
                            <audio controls="controls">
                                <source src="audio/mf/mf_demo4.mp3" autoplay />Your browser does not support the audio
                                element.
                            </audio>
                            <figure>
                                <figcaption>Demo 4 (melody)</figcaption>
                                <img src="rebuttal_materials/ssm_demo/mf_demo4.png">
                            </figure>

                            <button class="collapsible">Show Other Tracks of demo 4</button>
                            <div class="colla_content">
                                <figure>
                                    <figcaption>Demo 4 (piano)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo4_piano.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 4 (guitar)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo4_guitar.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 4 (string)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo4_string.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 4 (bass)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo4_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>Demo 4 (percussion)</figcaption>
                                    <img src="rebuttal_materials/ssm_demo/mf_demo4_percussion.png">
                                </figure>
                            </div>
                        </section>

                        <section id="ssm_train">
                            <h3>Training Samples</h3>
                            We also show the SSMs of 3 randomly picked training samples FYI. Please click the following
                            buttons to see them:

                            <button class="collapsible">Training Sample 1</button>
                            <div class="colla_content">
                                <table>
                                    <tbody>
                                        <tr>
                                            <td><audio controls="controls">
                                                    <source src="rebuttal_materials/train/audio/train1.mp3" autoplay />
                                                    Your browser does not support the
                                                    audio element.
                                                </audio></td>
                                            <td><a href="rebuttal_materials/train/midi/train1.mid">midi</a></td>
                                        </tr>
                                    </tbody>
                                </table>

                                <figure>
                                    <figcaption>training sample 1 (melody)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train1.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 1 (piano)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train1_piano.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 1 (bass)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train1_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 1 (percussion)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train1_percussion.png">
                                </figure>
                            </div>

                            <button class="collapsible">Training Sample 2</button>
                            <div class="colla_content">
                                <table>
                                    <tbody>
                                        <tr>
                                            <td><audio controls="controls">
                                                    <source src="rebuttal_materials/train/audio/train2.mp3" autoplay />
                                                    Your browser does not support the
                                                    audio element.
                                                </audio></td>
                                            <td><a href="rebuttal_materials/train/midi/train2.mid">midi</a></td>
                                        </tr>
                                    </tbody>
                                </table>

                                <figure>
                                    <figcaption>training sample 2 (melody)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train2.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 2 (guitar)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train2_guitar.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 2 (bass)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train2_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 2 (percussion)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train2_percussion.png">
                                </figure>
                            </div>

                            <button class="collapsible">Training Sample 3</button>
                            <div class="colla_content">
                                <table>
                                    <tbody>
                                        <tr>
                                            <td><audio controls="controls">
                                                    <source src="rebuttal_materials/train/audio/train3.mp3" autoplay />
                                                    Your browser does not support the
                                                    audio element.
                                                </audio></td>
                                            <td><a href="rebuttal_materials/train/midi/train3.mid">midi</a></td>
                                        </tr>
                                    </tbody>
                                </table>

                                <figure>
                                    <figcaption>training sample 3 (melody)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train3.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 3 (piano)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train3_piano.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 3 (guitar)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train3_guitar.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 3 (bass)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train3_bass.png">
                                </figure>
                                <figure>
                                    <figcaption>training sample 3 (percussion)</figcaption>
                                    <img src="rebuttal_materials/train/ssm/train3_percussion.png">
                                </figure>
                            </div>
                        </section>

                        <br />
                        <p>From the SSMs of the generated demos, we can see that there are many similar bars in the
                            demos, and the music pieces tend to repeat or
                            imitate the previous bars at the distance of 1, 2, 4, 8, ..., which manifests reasonable
                            structures. Note that there are also many places where the similarities are larger than 0.0
                            and
                            less than 1, and it means that these bars are similar and also have variations between them.
                            If
                            you watch the videos on <a href="https://museformer.github.io/">the demo page</a>, you will
                            also
                            find that there are many variations on the melody track, let alone that in many cases, the
                            accompaniment tracks can be completely different for the similar melody. Therefore,
                            Museformer
                            can model both repetitions and variations, the combination of which makes good music
                            structures
                            of the generated music.</p>

                        <p>If we compare different tracks of a generated demo, we can see that, in general, the melody
                            tends to repeat at a specific distance, while the accompaniment tracks usually follow a
                            simple pattern and repeat more. This also fits our experiences in music. However, this is
                            not always true for every song. For example, the bass track of demo 1 rarely repeat, which
                            is mainly due to the bass is only played in a few bars. Also, the similarity pattern is
                            different for every song, showing the diversity of music.</p>

                        <p>Also, we can see that the generated demos manifest similar characteristics to the training
                            samples. It indicates that our method can successfully model the music structures.</p>


                    </section>

                    <section id="maestro">
                        <h2>Experiments on Maestro</h2>
                        
                        <section id="maestro_results">
                            <h3>Results</h3>
                            The following table shows the results of objective evaluation, where perplexity (PPL) is used as the metric.
                            <table>
                                <thead>
                                    <tr>
                                        <th style="text-align: center"></th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">PPL (1,024)</th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">PPL (5,120)</th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">PPL (10,240)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td style="text-align: left">Music Transformer</td>
                                        <td>5.04</td>
                                        <td>10.92</td>
                                        <td>13.17</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Transformer-XL</td>
                                        <td><b>4.16</b></td>
                                        <td>4.17</td>
                                        <td>4.18</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Longformer</td>
                                        <td>4.17</td>
                                        <td>4.26</td>
                                        <td>4.30</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Linear Transformer</td>
                                        <td>5.06</td>
                                        <td>5.22</td>
                                        <td>5.33</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Museformer (ours)</td>
                                        <td><b>4.16</b></td>
                                        <td><b>4.12</b></td>
                                        <td><b>4.12</b></td>
                                    </tr>
                                </tbody>
                            </table>

                            The following table shows the results of subjective evaluation, where we use the metrics presented in the paper.
                            <table>
                                <thead>
                                    <tr>
                                        <th style="text-align: center"></th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">Musicality</th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">ST Structure</th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">LT Structure</th>
                                        <th style="text-align: center; padding-left: 80px; padding-right: 80px;">Overall</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td style="text-align: left">Music Transformer</td>
                                        <td>4.50±1.12</td>
                                        <td>4.33±1.11</td>
                                        <td>3.00±0.82</td>
                                        <td>4.67±1.37</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Transformer-XL</td>
                                        <td>5.17±1.67</td>
                                        <td>4.50±1.50</td>
                                        <td><b>3.83±1.67</b></td>
                                        <td>5.33±1.25</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Longformer</td>
                                        <td>5.00±1.53</td>
                                        <td>4.67±0.75</td>
                                        <td>3.33±1.11</td>
                                        <td>5.00±1.63</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Linear Transformer</td>
                                        <td>4.83±1.57</td>
                                        <td>4.00±1.15</td>
                                        <td>3.50±1.26</td>
                                        <td>4.83±2.27</td>
                                    </tr>
                                    <tr>
                                        <td style="text-align: left">Museformer (ours)</td>
                                        <td><b>5.50±1.12</b></td>
                                        <td><b>4.83±1.07</b></td>
                                        <td><b>3.83±0.90</b></td>
                                        <td><b>5.67±1.60</b></td>
                                    </tr>
                                </tbody>
                            </table>

                        </section>

                        <section id="maestro_analysis">
                            <h3>Analysis</h3>
                            The following figure shows the score of a MIDI file in the Maestro dataset. The note onsets and durations are not calibrated, which is an obvious problem existed in almost all samples in this dataset. This problem makes it hard to accurately model the music structures.

                            <figure>
                                <img src="rebuttal_materials/maestro/maestro_sheet-01.png">
                            </figure>

                            We also compute the similarity distribution on the Maestro dataset using the approach introduced in <a href="#dataset_analysis">the first section</a>, as shown in the following figure. Note that the ordinate numbers are very small, which indicates that the similarity between each pair of bars is very small and thus this dataset shows nearly no music structures in the samples. 

                            <figure>
                                <img src="rebuttal_materials/maestro/maestro.png">
                            </figure>

                        </section>

                    </section>


                    <br /><br /><br />
                    <p>If anything is not clear enough to you, please feel free to ask us or have a discussion
                        with us.</p>
                    <p>Thank you for everything &#128151;!</p>

                    </section>

                </article>
            </div>
            <nav class="section-nav">
                <ol>
                    <li><a href="#introduction">Introduction</a></li>
                    <li><a href="#dataset_analysis">Similarity Distribution on Different Datasets</a>
                        <ul>
                            <li class=""><a href="#dataset_analysis_lmd">LMD (TopMAGD)</a></li>
                            <li class=""><a href="#dataset_analysis_symphony">Symphony</a></li>
                        </ul>
                    </li>
                    <li><a href="#music_analysis">Similarity Distribution on Generated Music</a></li>
                    <li><a href="#ssm">Self-Similarity Matrix of Demos</a>
                        <ul>
                            <li class=""><a href="#ssm_demo1">Demo 1</a></li>
                            <li class=""><a href="#ssm_demo2">Demo 2</a></li>
                            <li class=""><a href="#ssm_demo3">Demo 3</a></li>
                            <li class=""><a href="#ssm_demo4">Demo 4</a></li>
                            <li class=""><a href="#ssm_train">Training Samples</a></li>
                        </ul>
                    </li>
                    <li><a href="#maestro">Experiments on Maestro</a>
                        <ul>
                            <li class=""><a href="#maestro_results">Results</a></li>
                            <li class=""><a href="#maestro_analysis">Analysis</a></li>
                        </ul>
                    </li>
                </ol>
            </nav>
        </main>
    </div>

    <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function () {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.maxHeight) {
                    content.style.maxHeight = null;
                } else {
                    content.style.maxHeight = content.scrollHeight + "px";
                }
            });
        }
    </script>


</body>

</html>